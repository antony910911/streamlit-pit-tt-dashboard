# streamlit_app.py - å®Œæ•´ä¿®æ­£ç‰ˆ Part 1

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np
import re
import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
import matplotlib.font_manager as fm
import pytz
import streamlit as st



# ==== å¼·åˆ¶å­—å‹è¨­å®š ====
import matplotlib.font_manager as fm
import matplotlib.pyplot as plt

font_path = "fonts/NotoSansTC-Regular.ttf"

try:
    fm.fontManager.addfont(font_path)
    font_prop = fm.FontProperties(fname=font_path)
    font_name = font_prop.get_name()

    plt.rcParams['font.sans-serif'] = [font_name]
    plt.rcParams['axes.unicode_minus'] = False

    print(f"âœ… ç¾åœ¨ç”¨å­—å‹ï¼š{font_name}")
except Exception as e:
    print(f"[WARNING] å­—å‹æ²’æŠ“åˆ°ï¼ŒFallbackï¼ŒException: {e}")
    plt.rcParams['font.sans-serif'] = ['sans-serif']

# ==== è‡ªå‹•çˆ¬ CSV å‡½æ•¸ ====
def fetch_csv_and_load_df(start_date, start_time, end_date, end_time):
    import datetime
    import chardet
    import zipfile
    import pytz

    tz = pytz.timezone("Asia/Taipei")
    start_datetime_obj = tz.localize(datetime.datetime.combine(start_date, start_time))
    end_datetime_obj = tz.localize(datetime.datetime.combine(end_date, end_time))

    startEpoch = int(start_datetime_obj.astimezone(pytz.utc).timestamp())
    endEpoch = int(end_datetime_obj.astimezone(pytz.utc).timestamp())

    query_url = "https://ah2e-txi.barn-pence.ts.net/csvquery"
    query_payload = {
        'startEpoch': startEpoch,
        'endEpoch': endEpoch,
        'interval': 5
    }

    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:124.0) Gecko/20100101 Firefox/124.0",
        "Referer": "https://main.d1iku9uvtgtqdy.amplifyapp.com/",
        "Origin": "https://main.d1iku9uvtgtqdy.amplifyapp.com",
        "Accept": "application/json, text/plain, */*",
        "Accept-Language": "zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "X-Requested-With": "XMLHttpRequest",
    })

    resp = session.post(query_url, json=query_payload)
    resp_json = resp.json()
    job_id = resp_json["jobId"]

    task_list_url = f"https://ah2e-txi.barn-pence.ts.net/query-status?job={job_id}"

    download_url = None
    with st.spinner("ç­‰å¾…ä»»å‹™å®Œæˆ..."):
        while True:
            resp = session.get(task_list_url)
            status_json = resp.json()
            task_status = status_json.get("status", "unknown")

            if task_status == "done":
                download_url = status_json["url"]
                break
            elif task_status == "error":
                raise Exception("ä»»å‹™å¤±æ•—")
            else:
                time.sleep(2)

    if download_url.startswith("/"):
        download_url = "https://ah2e-txi.barn-pence.ts.net" + download_url

    if download_url.endswith(".zip"):
        zip_resp = session.get(download_url)
        zip_filename = "downloaded_data.zip"
        with open(zip_filename, 'wb') as f:
            f.write(zip_resp.content)

        with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
            csv_inside_name = [name for name in zip_ref.namelist() if name.endswith(".csv")][0]
            zip_ref.extract(csv_inside_name, ".")
            csv_filename = csv_inside_name
    else:
        csv_resp = session.get(download_url)
        csv_filename = "downloaded_data.csv"
        with open(csv_filename, 'wb') as f:
            f.write(csv_resp.content)

    st.success(f"âœ… è³‡æ–™ä¸‹è¼‰å®Œæˆï¼š{csv_filename}")

    with open(csv_filename, 'rb') as f_detect:
        raw_data = f_detect.read(500)
        result = chardet.detect(raw_data)
        detected_encoding = result['encoding']
        safe_encoding = detected_encoding or "utf-8-sig"

    with open(csv_filename, 'r', encoding=safe_encoding) as f:
        line1 = f.readline().strip().split(",")
        line2 = f.readline().strip().split(",")
        max_len = max(len(line1), len(line2))
        line1 += [""] * (max_len - len(line1))
        line2 += [""] * (max_len - len(line2))
        combined_columns = [f"{eng.strip()} / {chi.strip()}" if chi.strip() else eng.strip() for eng, chi in zip(line1, line2)]

    df = pd.read_csv(csv_filename, skiprows=2, names=combined_columns, low_memory=False, encoding=safe_encoding)

    timestamp_col = combined_columns[1]

    df["Datetime"] = pd.to_datetime(df[timestamp_col], unit="s", utc=True).dt.tz_convert("Asia/Taipei").dt.tz_localize(None)

    df.set_index("Datetime", inplace=True)


    return df, combined_columns

# ==== è¼”åŠ©å‡½æ•¸ï¼šåªè®€æ¬„ä½å®šç¾© ====
def load_columns_only():
    dummy_date = pd.Timestamp.today().date()
    df_dummy, columns_dummy = fetch_csv_and_load_df(
        start_date=dummy_date,
        start_time=pd.to_datetime("00:00").time(),
        end_date=dummy_date,
        end_time=pd.to_datetime("00:05").time()
    )
    return columns_dummy


# ==== åˆå§‹åŒ– Session State ====
if "df_all" not in st.session_state:
    st.session_state.df_all = None
    st.session_state.all_columns = None
    st.session_state.query_start_date = None
    st.session_state.query_start_time = None
    st.session_state.query_end_date = None
    st.session_state.query_end_time = None






st.set_page_config(
    page_title="å°ä»¥ä¹¾å¼å­æ°§é†±é…µæ•¸æ“šåˆ†æ",
    layout="wide",
    initial_sidebar_state="collapsed"
)



# ==== Tabs ==== åŠ ä¸Š query_params æ§åˆ¶ç›®å‰åœ¨å“ªå€‹ tab
query_params = st.experimental_get_query_params()
selected_tab = query_params.get("tab", ["é¦–é "])[0]

tab_names = ["é¦–é ", "åˆ†æåŠŸèƒ½", "PIT/TTå¤šæ—¥è®ŠåŒ–è¶¨å‹¢"]
tab_idx = tab_names.index(selected_tab) if selected_tab in tab_names else 0

tabs = st.tabs(tab_names)

# å¯«å›ç›®å‰ tab (ä¿æŒåŒæ­¥ï¼Œè®“æ‰‹å‹•é» tab ä¹Ÿæœƒå¯«å…¥ç¶²å€)
st.experimental_set_query_params(tab=tab_names[tab_idx])

# ==== é¦–é  ====
with tabs[0]:
    st.title("å°ä»¥ä¹¾å¼å­æ°§é†±é…µæ•¸æ“šåˆ†æ")
    st.markdown("""
    ### ä½¿ç”¨èªªæ˜
    æ­¡è¿ä½¿ç”¨æœ¬æ‡‰ç”¨ç¨‹å¼ï¼  
    ä»¥ä¸‹æ˜¯åŸºæœ¬æ“ä½œæŒ‡å—ï¼š

    1. é»æ“Šå·¦ä¸Šæ–¹å°ç®­é ­  
    2. é¸æ“‡éœ€è¦åˆ†æçš„æ™‚é–“å€é–“ 
    3. å†åˆ°åˆ†æåŠŸèƒ½é é¢èª¿æ•´åœ–è¡¨é¡¯ç¤ºåƒæ•¸  
    4. æŸ¥çœ‹çµæœä¸¦å­˜æª” ğŸ‰

    **æ³¨æ„äº‹é …ï¼š**  
    - æŸ¥è©¢æ™‚é–“å€é–“éœ€å¤§æ–¼20åˆ†é˜æ‰çœ‹çš„åˆ°åœ–å–”ï¼ˆå› ç¨‹å¼é è¨­æé ­å»å°¾å„5åˆ†é˜ï¼‰

    ---
    """)

with tabs[1]:
    st.title("åˆ†æåŠŸèƒ½")    

    st.sidebar.title("âš™ï¸ è¨­å®šé¸é … - è³‡æ–™æŸ¥è©¢")
    
    start_date = st.sidebar.date_input("é–‹å§‹æ—¥æœŸ")
    start_time = st.sidebar.time_input("é–‹å§‹æ™‚é–“")
    end_date = st.sidebar.date_input("çµæŸæ—¥æœŸ")
    end_time = st.sidebar.time_input("çµæŸæ™‚é–“")

    if st.sidebar.button("æŸ¥è©¢è³‡æ–™"):
        df, columns = fetch_csv_and_load_df(start_date, start_time, end_date, end_time)
        st.session_state.df_all = df
        st.session_state.all_columns = columns
        st.session_state.query_start_date = start_date
        st.session_state.query_start_time = start_time
        st.session_state.query_end_date = end_date
        st.session_state.query_end_time = end_time
    # ğŸš€ é€™ä¸€è¡Œ â†’ å¼·åˆ¶è·³åˆ°åˆ†æåŠŸèƒ½ tab
        st.experimental_set_query_params(tab="åˆ†æåŠŸèƒ½")


    # ç”¨ session_state çš„è³‡æ–™
    df_all = st.session_state.get("df_all")
    all_columns = st.session_state.get("all_columns")
    query_start_date = st.session_state.get("query_start_date")
    query_start_time = st.session_state.get("query_start_time")
    query_end_date = st.session_state.get("query_end_date")
    query_end_time = st.session_state.get("query_end_time")



    

    if df_all is not None and all_columns is not None:
    # é€²å…¥ç•«åœ–æ®µ

        # === åˆ†æåŠŸèƒ½é å°ˆå±¬ sidebar è¨­å®š ===
        st.sidebar.title("ğŸ–Œï¸ åœ–è¡¨è¨­å®š")
        # â†’ æ¥ä¸‹ä¾†ä½ çš„ sampling_interval_display åˆ°ç•«åœ–çš„æ•´æ®µ code å…¨éƒ¨æ”¾åœ¨é€™é‚Š
            # ==== å–æ¨£é–“éš” ====
        sampling_interval_display = st.sidebar.selectbox(
            "å–æ¨£é–“éš” (Resample)",
            ["5ç§’", "10ç§’", "30ç§’", "1åˆ†é˜", "5åˆ†é˜", "15åˆ†é˜"],
            index=4
        )
        sampling_interval_map = {
            "5ç§’": "5s",
            "10ç§’": "10s",
            "30ç§’": "30s",
            "1åˆ†é˜": "1min",
            "5åˆ†é˜": "5min",
            "15åˆ†é˜": "15min",
        }
        sampling_interval = sampling_interval_map[sampling_interval_display]
        # ==== X è»¸ä¸»åˆ»åº¦ ====
        x_axis_interval = st.sidebar.selectbox(
            "X è»¸ä¸»åˆ»åº¦é–“è·",
            ["10åˆ†é˜","30åˆ†é˜", "1å°æ™‚", "2å°æ™‚", "3å°æ™‚", "4å°æ™‚", "6å°æ™‚", "12å°æ™‚", "1å¤©", "7å¤©"],
            index=2  # 0 æ˜¯ "10åˆ†é˜"
        )
        interval_map = {
            "10åˆ†é˜": mdates.MinuteLocator(interval=10),
            "30åˆ†é˜": mdates.MinuteLocator(interval=30),
            "1å°æ™‚": mdates.HourLocator(interval=1),
            "2å°æ™‚": mdates.HourLocator(interval=2),
            "3å°æ™‚": mdates.HourLocator(interval=3),
            "4å°æ™‚": mdates.HourLocator(interval=4),
            "6å°æ™‚": mdates.HourLocator(interval=6),
            "12å°æ™‚": mdates.HourLocator(interval=12),
            "1å¤©": mdates.DayLocator(interval=1),
            "7å¤©": mdates.DayLocator(interval=7),
        }
        x_major_locator = interval_map.get(x_axis_interval, mdates.HourLocator(interval=1))

        # ==== Y è»¸å€é–“è¨­å®š ====
        pit_tt_y_axis_mode = st.sidebar.radio("PIT / TT Y è»¸å€é–“", ["Auto", "å›ºå®š 0~1", "è‡ªè¨‚ min/max"])
        y_min_custom = None
        y_max_custom = None
        if pit_tt_y_axis_mode == "è‡ªè¨‚ min/max":
            y_min_custom = st.sidebar.number_input("è‡ªè¨‚ Y è»¸æœ€å°å€¼", value=0.0)
            y_max_custom = st.sidebar.number_input("è‡ªè¨‚ Y è»¸æœ€å¤§å€¼", value=1.0)

        # ==== å­—é«”å¤§å° ====
        font_size = st.sidebar.slider("å­—é«”å¤§å°", 10, 26, 18)
        line_w = st.sidebar.slider("ç·šæ¢ç²—ç´° (PIT/TT)", 1, 10, 2)

        # ==== PIT/TT é¸æ“‡ ====
        available_pit_tt_prefixes = sorted(list(set(
            [col.split(" / ")[0] for col in all_columns if col.startswith("pit-") or col.startswith("tt-")]
        )))
        default_pit_columns = ["pit-311a", "pit-311c", "pit-312a", "pit-312c"]

        selected_pit_tt_prefixes = st.sidebar.multiselect(
            "é¸æ“‡ PIT / TT æ¬„ä½ (å¯è¤‡é¸)",
            available_pit_tt_prefixes,
            default=default_pit_columns
        )

        pit_cols = []
        for col_prefix in selected_pit_tt_prefixes:
            full_col = [col for col in all_columns if col.startswith(col_prefix)][0]
            pit_cols.append(full_col)

        # ==== è¨­å‚™é¸æ“‡ ====
        excluded_prefixes = ["id", "time", "date", "timestamp"]
        available_equipment_prefixes = sorted(list(set(
            [
                col.split(" / ")[0]
                for col in all_columns
                if not (col.startswith("pit-") or col.startswith("tt-"))
                and not any(col.lower().startswith(ex_prefix) for ex_prefix in excluded_prefixes)
            ]
        )))
        default_equipment_cols = ["av-303a", "av-303c", "p-303a", "p-304a", "b-311a"]

        selected_equipment_prefixes = st.sidebar.multiselect("é¸æ“‡è¨­å‚™ (å¯è¤‡é¸)", available_equipment_prefixes, default=default_equipment_cols)

        equipment_cols_full = []
        for col_prefix in selected_equipment_prefixes:
            full_col = [col for col in all_columns if col.startswith(col_prefix)][0]
            equipment_cols_full.append(full_col)



    

        # ==== è½‰æ›è¨­å‚™ç‹€æ…‹æ¬„ä½ ====
        def convert_running_state(val):
            val_str = str(val).strip().replace("'", "")
            val_str = re.sub(r"[^\d]", "", val_str)
            val_str = val_str.zfill(4)
            if len(val_str) != 4:
                return 0
            return 1 if (val_str[1] == "1" or val_str[3] == "1") else 0

        for col in equipment_cols_full:
            df_all[col + "_running"] = df_all[col].apply(convert_running_state)

        # ğŸš« ä¸è¦åŠ  pytz / ä¸è¦åŠ  tz_localize

        start_datetime = pd.to_datetime(f"{query_start_date} {query_start_time}")
        end_datetime = pd.to_datetime(f"{query_end_date} {query_end_time}")


        df_plot = df_all.loc[(df_all.index >= start_datetime) & (df_all.index <= end_datetime)]
        st.write(f"âœ… æ“·å–æ™‚é–“æ®µï¼š{start_datetime} ï½ {end_datetime}ï¼Œç¸½ç­†æ•¸ï¼š{len(df_plot)}")





        # é¡å¤–æ¬„ä½ï¼šFIT-311-VOL é¡¯ç¤º
        fit_col_candidates = [col for col in all_columns if col.startswith("fit-311-vol")]
        fit_col = fit_col_candidates[0] if len(fit_col_candidates) > 0 else None
        show_fit = st.sidebar.checkbox("é¡¯ç¤º fit-311-vol / æ²¼æ°£ç¸½é‡", value=False, key="show_fit_checkbox")



        # ==== ç¹ªåœ– ====
        fig, ax1 = plt.subplots(figsize=(24, 14))

        resample_cols = pit_cols.copy()
        if show_fit and fit_col and fit_col in df_plot.columns:
            resample_cols.append(fit_col)

        if len(resample_cols) > 0:
            df_pit_resampled = df_plot[resample_cols].resample(sampling_interval).mean()
            df_pit_resampled = df_pit_resampled.asfreq(sampling_interval)

            trim_delta = pd.Timedelta(minutes=5)
            trim_start = start_datetime + trim_delta
            trim_end = end_datetime - trim_delta
            trim_mask = (df_pit_resampled.index >= trim_start) & (df_pit_resampled.index <= trim_end)
        else:
            df_pit_resampled = pd.DataFrame()  # ç©º df
            trim_mask = pd.Series([False])  # é¿å…å¾Œé¢ç•«åœ–å ±éŒ¯


        # ==== æ¨™é¡Œ & Y æ¨™ç±¤ ====
        sampling_interval_display_map = {
            "5s": "5 ç§’",
            "10s": "10 ç§’",
            "30s": "30 ç§’",
            "1min": "1 åˆ†é˜",
            "5min": "5 åˆ†é˜",
            "15min": "15 åˆ†é˜",
        }
        sampling_interval_display = sampling_interval_display_map.get(sampling_interval, sampling_interval)

        if all(col.startswith("pit-") for col in selected_pit_tt_prefixes):
            y_label = "PIT è¶¨å‹¢åœ– (kPa)"
            plot_title = f"PIT è¶¨å‹¢åœ– (å–æ¨£é–“éš”ï¼š{sampling_interval_display})\n{start_datetime} ~ {end_datetime}"
        elif all(col.startswith("tt-") for col in selected_pit_tt_prefixes):
            y_label = "TT è¶¨å‹¢åœ– (Â°C)"
            plot_title = f"TT è¶¨å‹¢åœ– (å–æ¨£é–“éš”ï¼š{sampling_interval_display})\n{start_datetime} ~ {end_datetime}"
        else:
            y_label = "PIT / TT è¶¨å‹¢åœ–"
            plot_title = f"PIT / TT è¶¨å‹¢åœ– (å–æ¨£é–“éš”ï¼š{sampling_interval_display})\n{start_datetime} ~ {end_datetime}"

        if len(equipment_cols_full) > 0:
            plot_title = plot_title.replace("è¶¨å‹¢åœ–", "è¶¨å‹¢åŠè¨­å‚™èµ·åœåœ–")

        # ==== PIT/TT è¶¨å‹¢ç·šåœ– ====ï¼ˆå«ç¬¬ 4 é» & ç¬¬ 5 é»ï¼‰====
        default_colors = [
        "#1f77b4", "#ff7f0e", "#2ca02c", "#d62728",
        "#9467bd", "#8c564b", "#e377c2", "#7f7f7f",
        "#bcbd22", "#17becf"
    ]

        # ç¬¬4é»ï¼šç·šæ¢æ˜¯å¦é¡¯ç¤º checkbox
        show_line_map = {}
        for col in pit_cols:
            show_line = st.sidebar.checkbox(f"é¡¯ç¤º {col}", value=True)
            show_line_map[col] = show_line

        # ç¬¬5é»ï¼šç·šæ¢é€æ˜åº¦
        line_alpha = st.sidebar.slider("ç·šæ¢é€æ˜åº¦ (PIT/TT)", 0.0, 1.0, 1.0, step=0.05)


        # ç·šæ¢é¡è‰²
        color_map_per_line = {}
        for i, col in enumerate(pit_cols):
            default_color = default_colors[i % len(default_colors)]
            selected_color = st.sidebar.color_picker(f"ç·šæ¢é¡è‰² - {col}", default_color)
            color_map_per_line[col] = selected_color

        # ==== ç•«ç·šï¼ˆå« PIT/TT & FITï¼‰====
        for col in pit_cols:
            if show_line_map.get(col, True):
                ax1.plot(
                    df_pit_resampled.index[trim_mask],
                    df_pit_resampled[col][trim_mask],
                    label=col,
                    linewidth=line_w,
                    color=color_map_per_line[col],
                    alpha=line_alpha
                )

        # é¡å¤–ç•« fit-311-vol
        if show_fit and fit_col in df_pit_resampled.columns:
            ax1.plot(
                df_pit_resampled.index[trim_mask],
                df_pit_resampled[fit_col][trim_mask],
                label="FIT-311-VOL / æ²¼æ°£ç¸½é‡",
                linewidth=line_w + 3,
                color="black",
                alpha=1.0,
                marker="o",
                markersize=10,
                markerfacecolor="black",
                markeredgecolor="black",
                markeredgewidth=1.5
            )


        # ==== X è»¸è¨­å®š ==== (å‹•æ…‹ DateFormatter)
        ax1.xaxis.set_major_locator(x_major_locator)

        if x_axis_interval in ["1å¤©", "7å¤©"]:
            ax1.xaxis.set_major_formatter(mdates.DateFormatter("%m-%d"))  # åªé¡¯ç¤ºæœˆ-æ—¥
        else:
            ax1.xaxis.set_major_formatter(mdates.DateFormatter("%m-%d %H:%M"))  # é¡¯ç¤º æœˆ-æ—¥ æ™‚:åˆ†

        tick_length = font_size * 0.5
        tick_width = font_size * 0.05
    
        # X è»¸
        ax1.tick_params(axis='x', labelsize=font_size + 4, length=tick_length, width=tick_width)
        plt.xticks(rotation=45)  # ä¸è¦å†å¦å¤–æŒ‡å®š fontsizeï¼Œtick_params å·²ç¶“è¨­å®šå¥½äº†


        # æº–å‚™ Y è»¸ç¯„åœè€ƒæ…®çš„æ¬„ä½
        y_axis_cols = pit_cols.copy()
        if show_fit and fit_col and fit_col in df_pit_resampled.columns:
            y_axis_cols.append(fit_col)

        # ==== Y è»¸ç¯„åœ robust ====
        if pit_tt_y_axis_mode == "å›ºå®š 0~1":
            ax1.set_ylim(0, 1)
        elif pit_tt_y_axis_mode == "è‡ªè¨‚ min/max":
            ax1.set_ylim(y_min_custom, y_max_custom)
        else:
            df_valid_columns = df_pit_resampled[y_axis_cols].dropna(axis=1, how='all')
            if not df_valid_columns.empty:
                y_min = df_valid_columns.min().min()
                y_max = df_valid_columns.max().max()
                print(f"[DEBUG] y_min={y_min}, y_max={y_max}")

                if np.isfinite(y_min) and np.isfinite(y_max):
                    ax1.set_ylim(y_min * 0.95, y_max * 1.05)
                else:
                    print("[WARNING] y_min or y_max is not finite, skipping set_ylim()")
            else:
                print("[WARNING] All selected columns are empty after dropna, skipping set_ylim()")

        # ==== X è»¸å€é–“ ==== â†’ ç”¨å®Œæ•´ start_datetime ~ end_datetime
        ax1.set_xlim(start_datetime, end_datetime)


        # ==== æ¨™é¡Œã€Xã€Y è»¸æ¨™ç±¤ ====
        ax1.set_xlabel("æ™‚é–“", fontsize=font_size + 6, labelpad=10, fontweight="bold")
        ax1.set_ylabel(y_label, fontsize=font_size + 6, labelpad=10, fontweight="bold")
        ax1.set_title(plot_title, fontsize=font_size + 17, pad=70, fontweight="bold")

        # Y è»¸
        ax1.tick_params(axis='y', labelsize=font_size + 4, length=tick_length, width=tick_width)

        # ==== åœ–ä¾‹ ====
        # è¨ˆç®—æœ‰å¹¾æ¢ç·š
        num_lines = len(pit_cols)
        # æ¯è¡Œæ”¾ 4 æ¢
        ncol = min(num_lines, 4)
        # ç®—å‡ºæœ‰å¹¾è¡Œ legend
        num_rows = int(np.ceil(num_lines / ncol))

        # å‹•æ…‹èª¿æ•´ legend y ä½ç½® & åœ–çš„ top
        # y_start è¶Šå¤§ â†’ legend é ä¸Šã€åœ–å€è¶Šå¤§
        legend_y_start = 0.92 + 0.01 * (num_rows - 1)  # æ¯å¤šä¸€è¡Œå¤šæ¨ä¸€é»ä¸Šå»
        top_adjust = 0.85 - 0.3 * (num_rows - 1)  # ä¸»åœ– top å¾€ä¸‹æ”¶ä¸€é»ï¼Œé¿å…æ“ åˆ° legend

        # åŠ  legend
        fig.legend(
            loc="upper center",
            bbox_to_anchor=(0.5, legend_y_start),
            ncol=ncol,
            fontsize=font_size + 4
        )
        # èª¿æ•´ä¸»åœ–ç¯„åœï¼Œtop è¦å‹•æ…‹
        plt.subplots_adjust(top=top_adjust)


        # ==== è¨­å‚™å•Ÿåœåœ– ====
        if len(equipment_cols_full) > 0:
            ax2 = ax1.twinx()
            y_positions = np.arange(len(equipment_cols_full))

            for i, col in enumerate(equipment_cols_full):
                state_series = df_plot[col + "_running"].fillna(0).astype(int)
                change_idx = state_series.ne(state_series.shift()).cumsum()

                for grp_id, grp_df in state_series.groupby(change_idx):
                    grp_state = grp_df.iloc[0]
                    grp_start_time = grp_df.index[0]
                    grp_end_time = grp_df.index[-1] + pd.Timedelta(seconds=5)
                    grp_end_time = min(grp_end_time, end_datetime)
                    color = "green" if grp_state == 1 else "red"

                    alpha_running = 0.3  # ç¶ è‰² (è¨­å‚™å•Ÿå‹•)
                    alpha_stopped = 0.3  # ç´…è‰² (è¨­å‚™åœæ­¢ â†’ æ·¡ä¸€é»)

                    color = "green" if grp_state == 1 else "red"
                    alpha_value = alpha_running if grp_state == 1 else alpha_stopped
                
                
                    ax2.axvspan(grp_start_time, grp_end_time,
                                    ymin=(i+0.1)/len(equipment_cols_full),
                                    ymax=(i+0.9)/len(equipment_cols_full),
                                    color=color, alpha=0.25)

            ax2.set_ylim(-0.5, len(equipment_cols_full)-0.5)
            ax2.set_yticks(y_positions)
            ax2.set_yticklabels(equipment_cols_full, fontsize=font_size + 4)
            ax2.set_ylabel("è¨­å‚™é‹ä½œç‹€æ…‹", fontsize=font_size + 6)

        # ==== å®Œæˆåœ–è¡¨ç¹ªè£½ ====
        plt.tight_layout()
        st.pyplot(fig, use_container_width=True)


with tabs[2]:
    st.title("ğŸ“… PIT/TT å¤šæ—¥è®ŠåŒ–è¶¨å‹¢ (å¯ä¸Šå‚³æŸ³ç‡Ÿæ°£æº«CSV)")

    import random
    import matplotlib.dates as mdates
    import pandas as pd
    import os

    # ==== è®€æ°£è±¡CSVå‡½æ•¸ ====
    def load_weather_csv(uploaded_file):
        if uploaded_file is not None:
           try:
               # å…ˆæª¢æŸ¥æ‰€æœ‰è¡Œ â†’ æ˜¯å¦ç‚º MH æ ¼å¼
                lines = uploaded_file.getvalue().decode("utf-8-sig").splitlines()
                is_mh_format = any(line.startswith("*") or line.startswith("#") for line in lines if line.strip() != "")

                if is_mh_format:
                    print(f"[INFO] åµæ¸¬åˆ° MH æ ¼å¼ â†’ è‡ªå‹•å°‹æ‰¾ header è¡Œ + è™•ç†")

                    # æ‰¾å‡º # header è¡Œ
                    header_line_idx = None
                    for idx, line in enumerate(lines):
                        if line.startswith("#"):
                            header_line_idx = idx
                            break

                    if header_line_idx is None:
                        raise ValueError("æ‰¾ä¸åˆ°æ¬„ä½åç¨±è¡Œ (# é–‹é ­) â†’ ç„¡æ³•è§£ææª”æ¡ˆï¼")

                    # ç¢ºèª header è¡Œå…§å®¹ â†’ åˆ—å°çœ‹çœ‹
                    print(f"[DEBUG] header line content: {lines[header_line_idx]}")

                    # è®€æª” â†’ å¾ header è¡Œä»¥ä¸‹é–‹å§‹
                    uploaded_file.seek(0)
                    df_weather = pd.read_csv(
                        uploaded_file,
                        skiprows=header_line_idx + 1,
                        names=["stno", "yyyymmddhh", "TX01"],
                        encoding="utf-8-sig"
                    )

                    # æ¿¾æ‰é•·åº¦ä¸ç­‰æ–¼10çš„ yyyymmddhh
                    df_weather = df_weather[df_weather["yyyymmddhh"].astype(str).str.len() == 10]

                    # ç¢ºèªç›®å‰æ¬„ä½æœ‰æ²’æœ‰ç©ºå€¼
                    print(f"[DEBUG] after length filter, df shape: {df_weather.shape}")
                    print(f"[DEBUG] any NA in yyyymmddhh? â†’ {df_weather['yyyymmddhh'].isna().sum()}")

                    # è½‰ ObsTime â†’ å¿…é ˆåŠ  errors="coerce"
                    df_weather["ObsTime"] = pd.to_datetime(
                        df_weather["yyyymmddhh"].astype(str),
                        format="%Y%m%d%H",
                        errors="coerce"  # é‡è¦ â†’ ä¿è­‰ä¸ç‚¸
                    )

                    # å†æ¿¾æ‰ ObsTime ç‚º NaT çš„è¡Œ â†’ ä¹¾æ·¨è³‡æ–™
                    df_weather = df_weather[df_weather["ObsTime"].notna()]

                    # è½‰ Time_dt
                    df_weather["Time_dt"] = df_weather["ObsTime"].map(
                        lambda t: pd.Timestamp(year=2000, month=1, day=1, hour=t.hour, minute=t.minute)
                    )

                    df_weather = df_weather.sort_values("Time_dt")
                    print(f"[INFO] ä½¿ç”¨ MH æ ¼å¼æª”æ¡ˆ è®€å–æ°£æº« â†’ {uploaded_file.name}")
                    return df_weather

                else:
                    print(f"[INFO] åµæ¸¬åˆ° æ¨™æº– CSV æ ¼å¼ â†’ ä½¿ç”¨ read_csv è§£æ")
                    uploaded_file.seek(0)
                    df_weather = pd.read_csv(
                        uploaded_file,
                        sep=None,
                        engine="python",
                        encoding="utf-8-sig",
                        on_bad_lines='warn'
                    )

                    # é˜²å‘†æª¢æŸ¥ â†’ æ˜¯å¦å« ObsTime æ¬„ä½
                    if "ObsTime" not in df_weather.columns:
                        raise ValueError("ä¸Šå‚³çš„æ¨™æº–CSVç¼ºå°‘ ObsTime æ¬„ä½ï¼Œè«‹ç¢ºèªæª”æ¡ˆæ ¼å¼æ˜¯å¦æ­£ç¢ºï¼ˆéœ€å« ObsTime æ¬„ä½ï¼‰ï¼")

                    df_weather["ObsTime"] = pd.to_datetime(
                        df_weather["ObsTime"],
                        format="%Y/%m/%d %H:%M",
                        errors="coerce"  # åŒæ¨£åŠ  errors="coerce"
                    )

                    df_weather = df_weather[df_weather["ObsTime"].notna()]  # drop NaT rows

                    df_weather["Time_dt"] = df_weather["ObsTime"].map(
                        lambda t: pd.Timestamp(year=2000, month=1, day=1, hour=t.hour, minute=t.minute)
                    )

                    df_weather = df_weather.sort_values("Time_dt")
                    print(f"[INFO] ä½¿ç”¨ ä¸Šå‚³CSV è®€å–æ°£æº« â†’ {uploaded_file.name}")
                    return df_weather

           except Exception as e:
                st.error(f"âŒ æ°£æº«CSVæª”æ ¼å¼éŒ¯èª¤ï¼Œç„¡æ³•è®€å–ï¼éŒ¯èª¤è¨Šæ¯: {e}")
                print(f"[ERROR] è®€CSVå¤±æ•—: {e}")
                return pd.DataFrame()
        else:
            print(f"[WARNING] å°šæœªä¸Šå‚³æ°£æº«CSV â†’ ä¸ç•«æ°£æº«ç·š")
            return pd.DataFrame()



    # ==== ç·šæ¢é è¨­é¡è‰²åˆ—è¡¨ï¼ˆå’ŒTab1ä¸€è‡´ï¼‰====
    default_colors = [
        "#1f77b4", "#ff7f0e", "#2ca02c", "#d62728",
        "#9467bd", "#8c564b", "#e377c2", "#7f7f7f",
        "#bcbd22", "#17becf"
    ]

    def random_color():
        return "#{:06x}".format(random.randint(0, 0xFFFFFF))

    if st.session_state.all_columns is None:
        st.session_state.all_columns = load_columns_only()

    if "tab3_df_cache" not in st.session_state:
        st.session_state.tab3_df_cache = {}

    if "tab3_color_per_date" not in st.session_state:
        st.session_state.tab3_color_per_date = {}

    if st.session_state.all_columns is not None:
        st.sidebar.title("âš™ï¸ å¤šæ—¥æ¯”å°è¨­å®š")

        date_options = pd.date_range(end=pd.Timestamp.today(), periods=14).strftime("%Y-%m-%d").tolist()
        selected_dates = st.sidebar.multiselect(
            "é¸æ“‡è¦æ¯”å°çš„æ—¥æœŸ (å¯å¤šé¸)",
            options=date_options,
            default=[date_options[-1], date_options[-2]]
        )

        if st.sidebar.button("ğŸ—‘ï¸ æ¸…é™¤è³‡æ–™Cache"):
            st.session_state.tab3_df_cache = {}
            st.success("âœ… å·²æ¸…é™¤ Tab3 è³‡æ–™Cache")

        available_pit_tt_prefixes = sorted(list(set(
            [col.split(" / ")[0] for col in st.session_state.all_columns if col.startswith("pit-") or col.startswith("tt-")]
        )))
        pit_tt_selected = st.sidebar.selectbox("é¸æ“‡ PIT / TT æ¬„ä½", available_pit_tt_prefixes)

        y_axis_mode = st.sidebar.radio("Y è»¸å€é–“", ["Auto", "å›ºå®š 0~1", "è‡ªè¨‚ min/max"])
        y_min_custom = None
        y_max_custom = None
        if y_axis_mode == "è‡ªè¨‚ min/max":
            y_min_custom = st.sidebar.number_input("è‡ªè¨‚ Y è»¸æœ€å°å€¼", value=0.0)
            y_max_custom = st.sidebar.number_input("è‡ªè¨‚ Y è»¸æœ€å¤§å€¼", value=1.0)

        sampling_interval_display = st.sidebar.selectbox(
            "å–æ¨£é–“éš” (Resample)",
            ["5ç§’", "10ç§’", "30ç§’", "1åˆ†é˜", "5åˆ†é˜", "10åˆ†é˜", "15åˆ†é˜"],
            index=4
        )
        sampling_interval_map = {
            "5ç§’": "5s",
            "10ç§’": "10s",
            "30ç§’": "30s",
            "1åˆ†é˜": "1min",
            "5åˆ†é˜": "5min",
            "10åˆ†é˜": "10min",
            "15åˆ†é˜": "15min",
        }
        sampling_interval = sampling_interval_map[sampling_interval_display]

        global_line_width = st.sidebar.slider("ç·šæ¢ç²—ç´° (å…¨éƒ¨ç·š)", 1, 10, 2)
        font_size = st.sidebar.slider("å­—é«”å¤§å° (åœ–è¡¨)", 10, 30, 18)
        show_weather = st.sidebar.checkbox("é¡¯ç¤ºæŸ³ç‡Ÿæ°£æº«æ›²ç·š", value=True)

        # ==== æ–°å¢ä¸Šå‚³æ°£æº«CSVæª” ====
        uploaded_weather_csv = st.sidebar.file_uploader("ä¸Šå‚³æ°£æº«CSVæª” (å« ObsTime,TX01 æ¬„ä½)", type=["csv"])

        color_per_date = st.session_state.tab3_color_per_date
        for i, date_str in enumerate(selected_dates):
            if date_str not in color_per_date:
                if i < len(default_colors):
                    color_per_date[date_str] = default_colors[i]
                else:
                    color_per_date[date_str] = random_color()

        for date_str in selected_dates:
            color_per_date[date_str] = st.sidebar.color_picker(
                f"ç·šæ¢é¡è‰² - {date_str}", color_per_date[date_str]
            )

        if st.button("ğŸš€ é–‹å§‹æ¯”å°") and len(selected_dates) > 0:
            fig, ax1 = plt.subplots(figsize=(20, 10))

            for date_str in selected_dates:
                date_obj = pd.to_datetime(date_str).date()

                if date_str in st.session_state.tab3_df_cache:
                    df_day = st.session_state.tab3_df_cache[date_str]
                    print(f"[CACHE] ä½¿ç”¨ cache è³‡æ–™ - {date_str}")
                else:
                    df_day, _ = fetch_csv_and_load_df(
                        start_date=date_obj,
                        start_time=pd.to_datetime("00:00").time(),
                        end_date=date_obj,
                        end_time=pd.to_datetime("23:59").time()
                    )
                    st.session_state.tab3_df_cache[date_str] = df_day
                    print(f"[FETCH] ä¸‹è¼‰è³‡æ–™ - {date_str}")

                full_col = [col for col in st.session_state.all_columns if col.startswith(pit_tt_selected)][0]

                df_day_resampled = df_day[[full_col]].resample(sampling_interval).mean()
                df_day_resampled = df_day_resampled.asfreq(sampling_interval)
                df_day_resampled = df_day_resampled.dropna()

                df_day_resampled["Time_dt"] = df_day_resampled.index.map(
                    lambda t: pd.Timestamp(year=2000, month=1, day=1, hour=t.hour, minute=t.minute, second=t.second)
                )
                df_day_resampled = df_day_resampled.sort_values("Time_dt")

                ax1.plot(
                    df_day_resampled["Time_dt"],
                    df_day_resampled[full_col],
                    label=f"{date_str}",
                    linewidth=global_line_width,
                    color=color_per_date[date_str]
                )

                # é è¨­å…ˆè¨­ç‚ºç©º â†’ ä¸ç•«å°±ç•¥é
                df_weather = pd.DataFrame()

                # åªæœ‰åœ¨æœ‰ä¸Šå‚³ä¸”ä½¿ç”¨è€…å‹¾é¸è¦ç•«æ°£æº«æ™‚æ‰è™•ç†
                if show_weather and uploaded_weather_csv is not None:
                    df_weather = load_weather_csv(uploaded_weather_csv)

                    if "ObsTime" in df_weather.columns:
                        df_weather["ObsTime"] = pd.to_datetime(df_weather["ObsTime"], errors="coerce")
                        df_weather = df_weather[df_weather["ObsTime"].notna()]
                        df_weather = df_weather[df_weather["ObsTime"].dt.date == date_obj]
                    else:
                        st.warning(f"âš ï¸ æª”æ¡ˆå…§ç¼ºå°‘ ObsTime æ¬„ä½ï¼Œç„¡æ³•è™•ç†æ°£æº«è³‡æ–™")
                        df_weather = pd.DataFrame()

                if show_weather and not df_weather.empty:
                    df_weather["TX01"] = pd.to_numeric(df_weather["TX01"], errors="coerce")

                    # ==== Resample æ°£æº«ç·š ====ï¼ˆé€™æ¨£æ‰æœƒè·Ÿ PIT/TT å°é½Šï¼‰
                    df_weather.set_index("ObsTime", inplace=True)
                    df_weather_resampled = df_weather[["TX01"]].resample(sampling_interval).mean()
                    df_weather_resampled = df_weather_resampled.asfreq(sampling_interval)
                    df_weather_resampled = df_weather_resampled.dropna()

                    df_weather_resampled["Time_dt"] = df_weather_resampled.index.map(
                        lambda t: pd.Timestamp(year=2000, month=1, day=1, hour=t.hour, minute=t.minute)
                    )
                    df_weather_resampled = df_weather_resampled.sort_values("Time_dt")

                    # ==== ç•«æ°£æº«ç·šï¼Œç”¨ color_per_date ====
                    ax1.plot(
                        df_weather_resampled["Time_dt"],
                        df_weather_resampled["TX01"],
                        label=f"{date_str} æŸ³ç‡Ÿæ°£æº«",
                        linewidth=2,
                        linestyle="--",           # ä¿ç•™è™›ç·š
                        marker='o',               # å¯¦å¿ƒåœ“é»
                        markersize=6,             # åœ“é»å¤§å°ï¼Œä½ å¯ä»¥èª¿æ•´ï¼Œå¸¸ç”¨ 5-8
                        markerfacecolor=color_per_date[date_str],  # åœ“é»å…§é¡è‰²
                        markeredgecolor=color_per_date[date_str],  # åœ“é»é‚Šæ¡†é¡è‰²
                        color=color_per_date[date_str]             # ç·šæ¢é¡è‰²
                    )



            ax1.xaxis.set_major_formatter(mdates.DateFormatter("%H:%M"))
            ax1.xaxis.set_major_locator(mdates.HourLocator(interval=1))
            ax1.set_xlim(pd.Timestamp("2000-01-01 00:00"), pd.Timestamp("2000-01-01 23:59"))

            # ==== èª¿å¤§ X/Yè»¸åˆ»åº¦å­—é«” ====
            tick_fontsize = font_size + 6

            ax1.tick_params(axis='x', labelsize=tick_fontsize)
            ax1.tick_params(axis='y', labelsize=tick_fontsize)
            plt.xticks(rotation=45)  # ä¸è¦å†å¦å¤–æŒ‡å®š fontsizeï¼Œtick_params å·²ç¶“è¨­å®šå¥½äº†
            if y_axis_mode == "å›ºå®š 0~1":
                ax1.set_ylim(0, 1)
            elif y_axis_mode == "è‡ªè¨‚ min/max":
                ax1.set_ylim(y_min_custom, y_max_custom)

            ax1.set_xlabel("æ™‚é–“ (HH:MM)", fontsize=font_size + 4, fontweight="bold")
            ax1.set_ylabel(full_col, fontsize=font_size + 4, fontweight="bold")
            # å‰¯æ¨™é¡Œæ¢ä»¶ï¼šåŒæ™‚å‹¾é¸é¡¯ç¤ºæ°£æº« + æœ‰ä¸Šå‚³CSV
            has_subtitle = show_weather and uploaded_weather_csv is not None

            # ä¸»æ¨™é¡Œ
            main_title = f"å¤šæ—¥è®ŠåŒ–è¶¨å‹¢æ¯”å° - {pit_tt_selected} (å–æ¨£é–“éš”ï¼š{sampling_interval_display})"
            ax1.set_title(main_title, fontsize=font_size + 10, fontweight="bold", pad=60 if has_subtitle else 40)

            # å‰¯æ¨™é¡Œ
            if has_subtitle:
                fig.text(
                    0.5,  # æ°´å¹³ç½®ä¸­
                    0.91, # ä¸»æ¨™é¡Œä¹‹ä¸Š
                    "æ¯”å°ä¸­å¤®æ°£è±¡å±€æŸ³ç‡Ÿæ°£è±¡ç«™(C0X320)æ°£æº«",
                    ha="center",
                    fontsize=font_size + 2
                )


            ax1.grid(True)
            st.pyplot(fig, use_container_width=True)
    else:
        st.warning("âš ï¸ ç„¡æ³•è®€å–æ¬„ä½å®šç¾©ï¼Œè«‹ç¨å¾Œé‡è©¦ã€‚")
